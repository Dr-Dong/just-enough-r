---
title: 'Summarising data'
output: 
  bookdown::tufte_html2
---



# Summarising data {#summarising-data}

```{r, include=FALSE, message=F}
# ignore all this for the moment; it will be explained below
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE, cache=TRUE)
library(tidyverse)
library(pander)
angry.moods <- readr::read_csv('data/angry_moods.csv')
```


Before you begin this section, make sure you have fully understood the section on [datasets and dataframes](datasets.html), and in particular that you are happy using the `%>%` symbol to describe a flow of data.

The chapter outlines several different approaches to obtaining summary statistics, and covers:

- Useful 'utility' functions
- Creating tables
- Using `dplyr` as a generalisable tool to make any kind of summary


In particular, we place an emphasis on functions *which return dataframes*, because this enables us to process and present our summaries in useful ways.







## Utility functions for descriptive statistics {-}



### Frequency tables {- #frequency-tables}


Let's say we ask 4 year olds and 6 year olds whether they prefer lego or duplo. We use the `table()` command to get a cross tabulation of these `age` categories and what the child `prefers`. We wrap `table(...)` in the `with()` function to tell it which dataframe to use:

```{r, include=F, echo=F}
set.seed(1234)
lego.duplo.df <- data_frame(prefers=c(rep("duplo", 50), rep("lego", 50)), age=c(rep("4 years", 38), rep("6 years", 42), rep("4 years", 20)) ) %>% sample_frac(., 1)
saveRDS(lego.duplo.df, file="lego.RDS")
```

```{r}
lego.table <- with(lego.duplo.df, table(age, prefers))
lego.table
```



### Summary statistics {-}


In this guide so far you might have notices functions which provide summaries of an entire dataframe. For example:

```{r}
summary(angry.moods)
```

Or:

```{r}
psych::describe(angry.moods, skew=FALSE)
```



Although useful, these functions miss two important elements:

1. We have to operate on the whole dataframe at once
2. The output is just printed to screen. We might prefer to get back a dataframe so that we can process the results further.



### Creating a data frame of summary statistics {-}

Thanksfully, many summary functions allow us to pass their results to the `as_data_frame()` function, which converts the output into a table which we can use like any other dataset.

In this example, we create summary statistics with the `psych::describe()` function, then convert to a dataframe and format as a table in RMarkdown:


```{r}
psych::describe(angry.moods, skew=FALSE) %>% 
  as_data_frame %>% 
  pandoc.table()
```


This summary table can be processed like any other dataframe. For instance, we can select columns and rows from it using `dplyr`:

```{r}
psych::describe(angry.moods, skew=FALSE) %>% 
  # rownames_to_column converts to a df but saves the 
  # row names in a new column for us, which can be useful
  rownames_to_column(var="variable") %>% 
  select(variable, mean, sd) %>% 
  filter(mean > 20) %>% 
  pandoc.table
```



##### Rownames are evil {.explainer}

Historically 'row names' were used on R to label individual rows in a dataframe. It turned out that this is generally a bad idea, because sorting and some summary functions would get very confused and mix up row names and the data itself.

It's generally considered best practice to avoid row names, and store everything as columns of data.

If you find that rownames in your data have disappeared, [see this guide for turning them into an extra column of data using `tibble::rownames_to_column()`](#rownames).





### Computing statistics by-groups {-}


```{r, error=T}
psych::describeBy(mtcars, 'cyl')
```

This is helpful, but there's no simple way to convert the result to a dataframe, which we will want if we are creating tables for publication.

`describeBy` actually returns a list of tables, one for each level of the `cyl` variable, so it is is possible to convert each table in turn:

```{r}
summary.tables <- psych::describeBy(mtcars, 'cyl')
summary.tables[[1]] %>% 
  as_data_frame() %>% 
  head(3)
```

But this is pretty yucky. Not only are the column names all mangled up, but we also have to think about extracting each levell in turn, and need to check how many levels in `cyl` there are. What happens if an extra level gets added? Our code will likely break.

Thankfully there is much nicer and more consistent way to compute exactly the summaries we want, sometimes termed the 'split, apply, combine' method.



## A generalised approach: Split, apply, combine {- #split-apply-combine}

The  `dplyr::` package, and especially the `summarise()` function provides a generalised way to create dataframes of frequencies and other summary statistics, grouped and sorted however we like.

For example, let's say we want the mean of some of our variables across the whole dataframe:

```{r}
angry.moods %>% 
  summarise(
    mean.anger.out=mean(Anger.Out), 
    sd.anger.out=sd(Anger.Out)
  )
```


This has returned a dataframe containing the statistics we need, although in this instance the dataframe only has one row. What if we want the numbers for men and women separately?

Utility functions like `describeBy` have options to do this (you would specify grouping variables in that). But there's a more general pattern at work --- we want to:

- *Split* our data (into men and women, or some other categorisation)
- *Apply* some function to them (e.g. calculate the mean) and then
- *Combine* it into a single table again (for more processing or analysis)


It's helpful to think of this *split $\rightarrow$ apply $\rightarrow$ combine* pattern whenever we are processing data because it *makes explicit what we want to do*.



#### Split: breaking the data into groups {-}

The first task is to organise our dataframe into the relevant groups. To do this we use `group_by()`:

```{r}
angry.moods %>% 
  group_by(Gender) %>% 
  head
```

Weirdly, this doesn't seem to have done anything. The data aren't sorted by `Gender`, and there is no visible sign of the grouping, but stick with it...


#### Apply and combine {-}
 
Continuing the example above, once we have grouped our data we can then *apply* a function to it â€” for exmaple, summarise:

```{r}
angry.moods %>% 
  group_by(Gender) %>% 
  summarise(
    mean.anger.out=mean(Anger.Out)
  )
```

And R and `dplyr` have done as we asked:

- *split* the data by `Gender`, using `group_by()`
- *apply* the `summarise()` function
- *combine* the results into a new data frame



#### A 'real' example {-}

In the previous section on datasets, we saw some found some raw data from a study which had measured depression with the PHQ-9. Patients were measured on numerous occasions (`month` is recorded) and were split into treatment and control groups:


```{r, mesage=F}
phq9.df <- readr::read_csv("phq.csv")
glimpse(phq9.df)
```


If this were our data we might want to:

- Calculate the sum of the PHQ-9 variables (the PHQ-9 *score*)
- Calculate the average PHQ-9 score at each month, and in each group
- Show these means by group for months 0, 7 and 12

Using only the commands above[^sneaked]  we can write:

[^sneaked]: You might have noticed I sneaked something new in here: the call to `pandoc.table()`. This is from the `pander::` package, which contains is a useful set of functions function for when writing RMarkdown documents. They convert many R objects into more readable output: here it makes a nice table for us in the compiled document.  We cover more [tips and tricks for formatting RMarkdown documents here](rmarkdown-tricks.html). You might also want to check [this page on missing values](missing-values.html) to explain the filter which uses `!is.na()`, but you could leave it for later.


```{r}
phq9.summary.df <- phq9.df %>% 
  mutate(phq9 = phq9_01 + phq9_02 + phq9_03 + 
                    phq9_04 + phq9_05 + phq9_06 + 
                    phq9_07 + phq9_08 + phq9_09) %>% 

  select(patient, group, month, phq9) %>% 
  # remove rows with missing values
  filter(!is.na(phq9)) %>% 
  # split
  group_by(month, group) %>% 
  # apply and combine
  summarise(phq.mean = mean(phq9))


phq9.summary.df %>% 
  filter(month %in% c(0, 7, 12)) %>% 
  pander::pandoc.table()
```



###### A 'neater way' {-}

You might have thought that typing out each variable in the above example (`phq9_01 + phq9_02...`) seemed a bit repetitive.

In general, if you find yourself typing something repetitive in R then there will a better way of doing it, and this is true here.

Stepping back, *what we want is the row mean of all the variables starting with `phq9_0`*. We can write this more concisely like so:

```{r}
phq9.df %>% 
  mutate(phq9 = rowMeans(
    select(phq9.df, starts_with("phq9_0"))
  )
)
```


I've broken the code into multiple lines to make it clearer to read. In English, this code means:

1. Take the the dataframe `phq9.df`
2. Add (using `mutate()`) a new variable called `phq` by
3. Calculating the rowmeans of selected columns in `phq9.df` which
4. Start with the letters: `phq9_0


[Ignore this if you are found the last section confusing, but if you find pipes useful then note that I explicitly passed the `phq9.df` directly to the `select()` function. There are other tricks with pipes where you can pass the intermediate result of a series of pipes to a function by putting a `.` (a full stop or period) as the argument to the function. This can be very useful, so see the [package documentation for details](https://github.com/tidyverse/magrittr).]{.explainer}






## Fancy reshaping {- #fancy-reshaping}

As noted in the section on [reshaping](#reshaping) above, it's common to combine the process of reshaping and aggregating or summarising in the same step. 

For example here we have multiple rows per person, 3 trial at time 1, and 3 more trials at time 2:

```{r, include=F}
expt.data <- readRDS("expt.data.csv") %>% filter(trial < 4)
```

```{r}
expt.data %>% 
  arrange(person, time, trial) %>% 
  head %>% 
  pander
```


We can reshape and aggregate this in a single step using `dcast`. Here we request the mean for each person at each time, with observations for each time split across two columns:

```{r, message=T, warning=T}
library(reshape2)
expt.data %>%
	dcast(person~paste0('time',time), 
	      fun.aggregate=mean) %>% 
  head %>% 
  pander
```

Here `dcast` has correctly guessed that `RT` is the value we want to aggregate (you can specify explicitly with the `value.var=` parameter).

`dcast` knows to aggregate using the mean because we set this with the `agg.function` parameter; this just stands for 'aggregation function'.

We don't have to request the mean though: any function will do. Here we request the SD instead:

```{r, message=T, warning=T}
expt.data %>%
	dcast(person~time, 
	      fun.aggregate=sd) %>% 
  head %>% 
  pander
```


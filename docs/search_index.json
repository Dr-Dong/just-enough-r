[
["anova.html", "6 Anova", " 6 Anova Be sure to read the section on linear models in R before you read this section, and specifically the parts on specifying models with formulae. This section attempts to cover in a high level way how to specify anova models in R and some of the issues in interpreting the model output. If you need to revise the basic idea of an Anova, the Howell textbook [@howell2016fundamental]. For a very quick reminder, this interactive/animated explanation of Anova is helpful. If you just want the ‘answers’ — i.e. the syntax to specify common Anova models – you could skip to the next section: Anova cookbook There are 4 rules for doing Anova in R and not wanting to cry: Keep your data in ‘long’ format. Know the differences between character, factor and numeric variables Do not use the aov() or anova() functions to get an Anova table unless you know what you are doing. Learn about the types of sums of squares and always remember to specify type=3, unless you know better. Rules for using Anova in R Rule 1: Use long format data In R, data are almost always most useful a long format where: each row of the dataframe corresponds to a single measurement occasion each column corresponds to a variable which is measured For example, in R we will have data like this: df %&gt;% head %&gt;% pander person time predictor outcome 1 1 7 12 1 2 7 10 1 3 7 8 2 1 3 20 2 2 3 12 2 3 3 10 Whereas in SPSS we might have the same data structured like this: df.wide %&gt;% head %&gt;% pander person predictor Time 1 Time 2 Time 3 1 7 12 10 8 2 3 20 12 10 3 8 1 5 9 4 3 8 7 18 5 4 9 12 17 6 5 6 6 14 R always uses long form data when running an Anova, but one downside is that it therefore has no automatic to know which rows belong to which person (assuming individual people are the unit of error in your model). This means that for repeated measures designs you need to make explicit which measures are repeated when specifying the model (see the section on repeated designs below). Rule 2: Know your variables See the section on dataframes and on the different column types and be sure you can distinguish: Numeric variables Factors Character strings. In Anova: Outcomes will be numeric variables Predictors will be factors or (preferably) character strings If you want to run Ancova models, you can also add numeric predictors. Rule 3: Don’t use aov() or anova() This is the most important rule of all. The aov and anova functions have been around in R a long time. For various historical reasons the defaults for these functions won’t do what you expect if you are used to SPSS, Stata, SAS, and most other stats packages. These differences are important and will be confusing and give you misleading results unless you understand them. The recommendation here is: If you have a factorial experiment define your model using lm() and then use car::Anova() to calculate F tests. If you have repeated measures, your data are perfectly balanced, and you have no missing values then use afex::car_aov(). If you think you want a repeated measures Anova but your data are not balanced, or you have missing data, use linear mixed models instead via the lme4:: package. Rule 4: Use type 3 sums of squares (and learn why) You may be aware, but there are at least 3 different ways of calculating the sums of squares for each factor and interaction in an Anova. In short, SPSS and most other packages use type 3 sums of squares. aov and anova use type 1. By default, car::Anova and ez::ezANOVA use type 2, but can use type 3 if you ask. This means you must: Make sure you use type 3 sums of squares unless you have a reason not to. Always pass type=3 as an argument when running an Anova. A longer explanation of why you probably want type 3 sums of squares is given in this online discussion on stats.stackechange.com and practical implications are shown in this worked example. An even longer answer, including a much deeper exploration of the philosophical questions involved is given by @venables1998exegeses. Recommendations for doing Anova Make sure to Plot your raw data first Where you have interactions, be cautious in interpreting the main effects in your model, and always plot the model predictions. If you find yourself aggregating (averaging) data before running your model, think about using a mixed or multilevel model instead. If you are using repeated measures Anova, check if you should should be using a mixed model instead. If you have an unbalanced design or any missing data, you probably should use a mixed model. "],
["anova-cookbook.html", "Anova ‘Cookbook’", " Anova ‘Cookbook’ This section is intended as a shortcut to running Anova for a variety of common types of model. If you want to understand more about what you are doing, read the section on principles of Anova in R first, or consult an introductory text on Anova which covers Anova [e.g. @howell2012statistical]. Between-subjects Anova Oneway Anova (&gt; 2 groups) If your design has more than 2 groups then you should use oneway Anova. Let’s say we asked people to taste 1 of 4 fruit juices, and rate how tasty it was on a scale from 0 to 10: We can run a oneway Anova with type 3 sums of squares using the Anova function from the car:: package: juice.lm &lt;- lm(tastiness ~ juice, data=tasty.juice) juice.anova &lt;- car::Anova(juice.lm, type=3) juice.anova Anova Table (Type III tests) Response: tastiness Sum Sq Df F value Pr(&gt;F) (Intercept) 615.04 1 114.4793 &lt; 2.2e-16 *** juice 128.83 3 7.9932 8.231e-05 *** Residuals 515.76 96 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 And we could compute the contasts for each fruit against the others (the grand mean): juice.lsm &lt;- emmeans::emmeans(juice.lm, pairwise~juice, adjust=&quot;fdr&quot;) juice.contrasts &lt;- emmeans::contrast(juice.lsm, &quot;eff&quot;) juice.contrasts$contrasts contrast estimate SE df t.ratio p.value Mango - Apple effect -1.90 0.6371203 96 -2.982 0.0060 Mango - Orange effect -1.54 0.5124993 96 -3.005 0.0060 Mango - Durian effect 1.02 0.3455270 96 2.952 0.0060 Apple - Orange effect -0.78 0.6371203 96 -1.224 0.2239 Apple - Durian effect 1.78 0.5124993 96 3.473 0.0046 Orange - Durian effect 1.42 0.6371203 96 2.229 0.0338 P value adjustment: fdr method for 6 tests We found a significant main effect of juice, F(3, 96) = 7.99, p &lt; .001. Followup tests (adjusted for false discovery rate) indicated that only Durian differed from the other juices, and was rated a significantly less tasty Mango, Apple, and Orange juice. Factorial Anova We are using a dataset from Howell [@howell2012statistical, chapter 13]: an experiment which recorded Recall among young v.s. older adults (Age) for each of 5 conditions. These data would commonly be plotted something like this: eysenck &lt;- readRDS(&quot;data/eysenck.Rdata&quot;) eysenck %&gt;% ggplot(aes(Condition, Recall, group=Age, color=Age)) + stat_summary(geom=&quot;pointrange&quot;, fun.data = mean_cl_boot) + ylab(&quot;Recall (95% CI)&quot;) + xlab(&quot;&quot;) Visual inspection of the data (see Figure X) suggested that older adults recalled more words than younger adults, and that this difference was greatest for the intention, imagery, and adjective conditions. Recall peformance was worst in the counting and rhyming conditions. Or alternatively if we wanted to provde a better summary of the distribution of the raw data we could use a boxplot: eysenck %&gt;% ggplot(aes(Age, Recall)) + geom_boxplot(width=.33) + facet_grid(~Condition) + ylab(&quot;Recall (95% CI)&quot;) + xlab(&quot;&quot;) Figure 6.1: Boxplot for recall in older and young adults, by condition. We can run a linear model including the effect of Age and Condition and the interaction of these variables, and calculate the Anova: eysenck.model &lt;- lm(Recall~Age*Condition, data=eysenck) car::Anova(eysenck.model, type=3) Anova Table (Type III tests) Response: Recall Sum Sq Df F value Pr(&gt;F) (Intercept) 490.00 1 61.0550 9.85e-12 *** Age 1.25 1 0.1558 0.6940313 Condition 351.52 4 10.9500 2.80e-07 *** Age:Condition 190.30 4 5.9279 0.0002793 *** Residuals 722.30 90 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Repeated measures or ‘split plot’ designs It might be controversial to say so, but the tools to run traditional repeat measures Anova in R are a bit of a pain to use. Although there are numerous packages simplify the process a little, their syntax can be obtuse or confusing. To make matters worse, various textbooks, online guides and the R help files themselves show many ways to achieve the same ends, and it can be difficult to follow the differences between the underlying models that are run. At this point, given the many other advantages of linear mixed models over traditional repeated measures Anova, and given that many researchers abuse traditional Anova in practice (e.g. using it for unbalanced data, or where some data are missing), the recommendation here is to simply give up and learn how to run linear mixed models. These can (very closely) replicate traditional Anova approaches, but also: Handle missing data or unbalanced designs gracefully and efficiently. Be expanded to include multiple levels of nesting. For example, allowing pupils to be nested within classes, within schools. Alternatively multiple measurements of individual patients might be clustered by hospital or therapist. Allow time to be treated as a continuous variable. For example, time can be modelled as a slope or some kind of curve, rather than a fixed set of observation-points. This can be more parsimonious, and more flexible when dealing with real-world data (e.g. from clinical trials). It would be best at this point to jump straight to the main section multilevel or mixed-effects models, but to give one brief example of mixed models in use: The sleepstudy dataset in the lme4 package provides reaction time data recorded from participants over a period of 10 days, during which time they were deprived of sleep. lme4::sleepstudy %&gt;% head(12) %&gt;% pander Reaction Days Subject 249.6 0 308 258.7 1 308 250.8 2 308 321.4 3 308 356.9 4 308 414.7 5 308 382.2 6 308 290.1 7 308 430.6 8 308 466.4 9 308 222.7 0 309 205.3 1 309 We can plot these data to show the increase in RT as sleep deprivation continues: lme4::sleepstudy %&gt;% ggplot(aes(factor(Days), Reaction)) + geom_boxplot() + xlab(&quot;Days&quot;) + ylab(&quot;RT (ms)&quot;) + geom_label(aes(y=400, x=2, label=&quot;you start to\\nfeel bad here&quot;), color=&quot;red&quot;) + geom_label(aes(y=450, x=9, label=&quot;imagine how bad\\nyou feel by this point&quot;), color=&quot;red&quot;) If we want to test whether there are significant differences in RTs between Days, we could fit something very similar to a traditional repeat measures Anova using the lme4::lmer() function, and obtain an Anova table for the model using the special lmerTest::anova() function: sleep.model &lt;- lmer(Reaction ~ factor(Days) + (1 | Subject), data=lme4::sleepstudy) lmerTest::anova(sleep.model) Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom Sum Sq Mean Sq NumDF DenDF F.value Pr(&gt;F) factor(Days) 166235 18471 9 153 18.703 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Traditional repeated measures Anova If you really need to fit the traditional repeated measures Anova (e.g. your supervisor/reviewer has asked you to) then you should use either the afex:: or ez:: packages. Let’s say we have an experiment where we record reaction 25 times (Trial) before and after (Time = {1, 2}) one of 4 experimental manipulations (Condition = {1,2,3,4}). You have 12 participants in each condition and no missing data: expt.data %&gt;% ggplot(aes(Condition, RT)) + geom_boxplot() + facet_wrap(~paste(&quot;Time&quot;, time)) We want to use our repeated measurements before and after the experimental interventions to increase the precision of our estimate of the between-condition differences. Our first step is to aggregate RTs for the multiple trials, taking the mean across all trials at a particular time: expt.data.agg &lt;- expt.data %&gt;% group_by(Condition, person, time) %&gt;% summarise(RT=mean(RT)) head(expt.data.agg) # A tibble: 6 x 4 # Groups: Condition, person [3] Condition person time RT &lt;fctr&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;dbl&gt; 1 1 1 1 260.8600 2 1 1 2 265.6524 3 1 2 1 279.1190 4 1 2 2 267.0095 5 1 3 1 254.3760 6 1 3 2 256.4459 Because our data are still in long form (we have two rows per person), we have to explicitly tell R that time is a within subject factor. Using the afex:: package we would write: expt.afex &lt;- afex::aov_car(RT ~ Condition * time + Error(person/time), data=expt.data.agg) Contrasts set to contr.sum for the following variables: Condition expt.afex$anova_table %&gt;% pander(caption=&quot;`afex::aov_car` output.&quot;) afex::aov_car output. num Df den Df MSE F ges Pr(&gt;F) Condition 3 44 158.6 159.4 0.8504 1.193e-23 time 1 44 144.6 11.87 0.114 0.001266 Condition:time 3 44 144.6 37.79 0.5513 3.073e-12 Using the ez:: package we would write: expt.ez &lt;- ez::ezANOVA(data=expt.data.agg, dv = RT, wid = person, within = time, between = Condition) expt.ez$ANOVA %&gt;% pander(caption=&quot;`ez::ezANOVA` output.&quot;) ez::ezANOVA output. Effect DFn DFd F p p&lt;.05 ges 2 Condition 3 44 159.4 1.193e-23 * 0.8504 3 time 1 44 11.87 0.001266 * 0.114 4 Condition:time 3 44 37.79 3.073e-12 * 0.5513 These are the same models: any differences in the output are simply due to rounding. You should use whichever of ez:: and afex:: you find easiest to understand The ges column is the generalised eta squared effect-size measure, which is preferable to the partial eta-squared reported by SPSS [@bakeman2005recommended]. But what about [insert favourite R package for Anova]? Lots of people like ez::ezANOVA and other similar packages. My problem with ezANOVA is that it doesn’t use formulae to define the model and for this reason encourages students to think of Anova as something magical and separate from linear models and regression in general. This guide is called ‘just enough R’, so I’ve mostly chosen to show only car::Anova because I find this the most coherent method to explain. Using formulae to specify the model reinforces a technique which is useful in many other contexts. I’ve make an exception for repeated because many people find specifying the error structure explicitly confusing and hard to get right, and so ez:: may be the best option in these cases. Comparison with a multilevel model For reference, a broadly equivalent (although not identical) multilevel model would be: expt.mlm &lt;- lmer(RT ~ Condition * time + (1|person), data=expt.data.agg) anova(expt.mlm) %&gt;% pander() Analysis of Variance Table of type III with Satterthwaite Sum Sq Mean Sq NumDF DenDF F.value Pr(&gt;F) Condition 69154 23051 3 44 159.4 0 time 1716 1716 1 44 11.87 0.001266 Condition:time 16394 5465 3 44 37.79 3.073e-12 Although with a linear mixed model it would also be posible to analyse the trial-by-trial data. Let’s hypothesise, for example, that subjects in Conditions 2 and 4 experienced a ‘practice effect’, such that their RTs reduced over multiple trials. If we plot the data, we can see this suspicion may be supported (how conveninent!): ggplot(expt.data, aes(trial, RT)) + geom_smooth() + facet_wrap(~paste(&quot;Condition&quot;, Condition)) `geom_smooth()` using method = &#39;loess&#39; If we wanted to replicate the aggregated RM Anova models shown above we could write: options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;)) expt.mlm2 &lt;- lmer(RT ~ Condition * time + (time|person), data=expt.data) anova(expt.mlm2) Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom Sum Sq Mean Sq NumDF DenDF F.value Pr(&gt;F) Condition 1391631 463877 3 64.082 129.803 &lt; 2.2e-16 *** time 32791 32791 1 71.596 9.176 0.00341 ** Condition:time 313212 104404 3 71.596 29.215 1.911e-12 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 But we can now add a continuous predictor for trial: expt.mlm.bytrial &lt;- lmer(RT ~ Condition * time * trial + (time|person), data=expt.data) anova(expt.mlm.bytrial) Analysis of Variance Table of type III with Satterthwaite approximation for degrees of freedom Sum Sq Mean Sq NumDF DenDF F.value Pr(&gt;F) Condition 181589 60530 3 591.06 17.3653 8.114e-11 *** time 7744 7744 1 670.24 2.2218 0.13655 trial 81015 81015 1 2339.99 23.2424 1.520e-06 *** Condition:time 94032 31344 3 670.24 8.9923 7.612e-06 *** Condition:trial 126361 42120 3 2339.99 12.0839 7.557e-08 *** time:trial 109 109 1 2339.99 0.0314 0.85943 Condition:time:trial 27086 9029 3 2339.99 2.5902 0.05125 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The significant Condition:trial term indicates that there was a difference in the practice effects between the experimental conditions. We found a significant interaction between condition and the linear term for trial number, F(3, 2340.18) = 10.83, p &lt; .001. We explored this effect by plotting model-estimated reaction times for each group for trials 1 through 25 (see Figure X): participants in condition 2 and 4 exprienced a greater reduction in RTs across trial, suggesting a larger practice effect for these conditions. `geom_smooth()` using method = &#39;loess&#39; `geom_smooth()` using method = &#39;loess&#39; `geom_smooth()` using method = &#39;loess&#39; See the multilevel models section for more details, including analyses which allow the effects of interventions to vary between participants (i.e., relaxing the assumption that an intervention will be equally effective for all participants). RM Anova v.s. multilevel models The RM Anova is perhaps more familiar, and may be conventional in your field which can make peer review easier (although in other fields mixed models are now expected where the design warrants it). RM Anova requires complete data: any participant with any missing data will be dropped from the analysis. This is problematic where data are expensive to collect, and where data re unlikely to be missing at random, for example in a clinical trial. In these cases RM Anova may be less efficient and more biased than an equivalent multilevel model. There is no simple way of calculating effect size measures like eta2 from the lmer model. This may or may not be a bad thing. @baguley2009standardized, for example, recommends reporting simple (rather than standardised) effect size measures, and is easily done by making predictions from the model. "],
["checking-assumptions.html", "Checking assumptions", " Checking assumptions The text below continues on from this example of factorial Anova. If we want to check that the assumptions of our Anova models are met, these tables and plots would be a reasonable place to start. First running Levene’s test: car::leveneTest(eysenck.model) %&gt;% pander() Levene’s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 9 1.031 0.4217 90 NA NA Then a QQ-plot of the model residuals to assess normality: car::qqPlot(eysenck.model) Figure 6.2: QQ plot to assess normality of model residuals And finally a residual-vs-fitted plot: data_frame( fitted = predict(eysenck.model), residual = residuals(eysenck.model)) %&gt;% # and then plot points and a smoothed line ggplot(aes(fitted, residual)) + geom_point() + geom_smooth(se=F) `geom_smooth()` using method = &#39;loess&#39; Figure 6.3: Residual vs fitted (spread vs. level) plot to check homogeneity of variance. For more on assumptions checks after linear models or Anova see: http://www.statmethods.net/stats/anovaAssumptions.html "],
["followup-tests.html", "Followup tests", " Followup tests The text below continues on from this example of factorial Anova. If we want to look at post-hoc pairwise tests we can use the the emmeans() function from the emmeans:: package. By default Tukey correction is applied for multiple comparisons, which is a reasonable default: em &lt;- emmeans::emmeans(eysenck.model, pairwise~Age:Condition) em$contrasts contrast estimate SE df t.ratio p.value Young,Counting - Older,Counting 0.5 1.26693 90 0.395 1.0000 Young,Counting - Young,Rhyming 0.1 1.26693 90 0.079 1.0000 Young,Counting - Older,Rhyming -0.6 1.26693 90 -0.474 1.0000 Young,Counting - Young,Adjective -4.0 1.26693 90 -3.157 0.0633 Young,Counting - Older,Adjective -7.8 1.26693 90 -6.157 &lt;.0001 Young,Counting - Young,Imagery -6.4 1.26693 90 -5.052 0.0001 Young,Counting - Older,Imagery -10.6 1.26693 90 -8.367 &lt;.0001 Young,Counting - Young,Intention -5.0 1.26693 90 -3.947 0.0058 Young,Counting - Older,Intention -12.3 1.26693 90 -9.709 &lt;.0001 Older,Counting - Young,Rhyming -0.4 1.26693 90 -0.316 1.0000 Older,Counting - Older,Rhyming -1.1 1.26693 90 -0.868 0.9970 Older,Counting - Young,Adjective -4.5 1.26693 90 -3.552 0.0205 Older,Counting - Older,Adjective -8.3 1.26693 90 -6.551 &lt;.0001 Older,Counting - Young,Imagery -6.9 1.26693 90 -5.446 &lt;.0001 Older,Counting - Older,Imagery -11.1 1.26693 90 -8.761 &lt;.0001 Older,Counting - Young,Intention -5.5 1.26693 90 -4.341 0.0015 Older,Counting - Older,Intention -12.8 1.26693 90 -10.103 &lt;.0001 Young,Rhyming - Older,Rhyming -0.7 1.26693 90 -0.553 0.9999 Young,Rhyming - Young,Adjective -4.1 1.26693 90 -3.236 0.0511 Young,Rhyming - Older,Adjective -7.9 1.26693 90 -6.236 &lt;.0001 Young,Rhyming - Young,Imagery -6.5 1.26693 90 -5.131 0.0001 Young,Rhyming - Older,Imagery -10.7 1.26693 90 -8.446 &lt;.0001 Young,Rhyming - Young,Intention -5.1 1.26693 90 -4.025 0.0044 Young,Rhyming - Older,Intention -12.4 1.26693 90 -9.787 &lt;.0001 Older,Rhyming - Young,Adjective -3.4 1.26693 90 -2.684 0.1963 Older,Rhyming - Older,Adjective -7.2 1.26693 90 -5.683 &lt;.0001 Older,Rhyming - Young,Imagery -5.8 1.26693 90 -4.578 0.0006 Older,Rhyming - Older,Imagery -10.0 1.26693 90 -7.893 &lt;.0001 Older,Rhyming - Young,Intention -4.4 1.26693 90 -3.473 0.0260 Older,Rhyming - Older,Intention -11.7 1.26693 90 -9.235 &lt;.0001 Young,Adjective - Older,Adjective -3.8 1.26693 90 -2.999 0.0950 Young,Adjective - Young,Imagery -2.4 1.26693 90 -1.894 0.6728 Young,Adjective - Older,Imagery -6.6 1.26693 90 -5.209 0.0001 Young,Adjective - Young,Intention -1.0 1.26693 90 -0.789 0.9986 Young,Adjective - Older,Intention -8.3 1.26693 90 -6.551 &lt;.0001 Older,Adjective - Young,Imagery 1.4 1.26693 90 1.105 0.9830 Older,Adjective - Older,Imagery -2.8 1.26693 90 -2.210 0.4578 Older,Adjective - Young,Intention 2.8 1.26693 90 2.210 0.4578 Older,Adjective - Older,Intention -4.5 1.26693 90 -3.552 0.0205 Young,Imagery - Older,Imagery -4.2 1.26693 90 -3.315 0.0411 Young,Imagery - Young,Intention 1.4 1.26693 90 1.105 0.9830 Young,Imagery - Older,Intention -5.9 1.26693 90 -4.657 0.0005 Older,Imagery - Young,Intention 5.6 1.26693 90 4.420 0.0011 Older,Imagery - Older,Intention -1.7 1.26693 90 -1.342 0.9409 Young,Intention - Older,Intention -7.3 1.26693 90 -5.762 &lt;.0001 P value adjustment: tukey method for comparing a family of 10 estimates Both cell means and pairwise contrasts are shown here. There is much more detail on computing pairwise comparisons and other types of contrasts in the section on multiple comparisons, including ways to extract and present your comparisons in APA format. "]
]

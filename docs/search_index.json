[
["covariance-modelling.html", "19 Covariance modelling", " 19 Covariance modelling The CFA examples were adapted from a guide originally produced by Jon May This section covers path analysis (path models), confirmatory factor analysis (CFA) and structural equation modelling (SEM). You are encouraged to work through the path models and CFA sections, and especially the material on assessing model fit, before tacking SEM. Before you start this either section make sure you have the lavaan package installed (see installing packages). install.packages(lavaan) And we load the package to make all the functions available with minimal typing: library(lavaan) "],
["path-models.html", "Path models", " Path models Path models are an extension of linear regression, but where multiple observed variables can be considered as ‘outcomes’. Because the terminology of outcomes v.s. predictors breaks down when variables can be both outcomes and predictors at the same time, it’s normal to distinguish instead between: Exogenous variables: those which are not predicted by any other Endogenous variables: variables which do have predictors, and may or may not predict other variales Defining a model To define a path model, lavaan requires that you specify the relationships between variables in a text format. A full guide to this lavaan model syntax is available on the project website. For path models the format is very simple, and resembles a series of linear models, written over several lines, but in text rather than as a model formula: # define the model over multiple lines for clarity mediation.model &lt;- &quot; y ~ x + m m ~ x &quot; In this case the ~ symbols just means ‘regressed on’ or ‘is predicted by’. The model in the example above defines that our outcome y is predicted by both x and m, and that x also predicts m. You might recognise this as a mediation model. Make sure you include the closing quote symbol, and also be careful when running the code which defines the model. RStdudio can sometimes get confused and only run some of the lines, leading to errors. The simplest solution is to select the entire block explicitly and run that. To fit the model we pass the model specification and the data to the sem() function: mediation.fit &lt;- sem(mediation.model, data=mediation.df) As we did for linear regression models, we have saved the model fit object into a variable, here named mediation.fit. To display the model results we can use summary(). The key section of the output to check is the table listed ‘Regressions’, which lists the regression parameters for the predictors for each of the endogenous variables. summary(mediation.fit) ## lavaan (0.5-23.1097) converged normally after 12 iterations ## ## Number of observations 200 ## ## Estimator ML ## Minimum Function Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 0.166 0.075 2.198 0.028 ## m 0.190 0.070 2.721 0.007 ## m ~ ## x 0.530 0.067 7.958 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.967 0.097 10.000 0.000 ## .m 0.993 0.099 10.000 0.000 From this table we can see that both x and m are significant predictors of y, and that x also predicts m. This implie that mediation is taking place, but see the mediation chapter for details of testing indirect effects in lavaan. Where’s the intercept? Path analysis is part of the set of techniques often termed ‘covariance modelling’. As the name implies the primary focus here is the relationships between variables, and less so the mean-structure of the variables. In fact, by default the software first creates the covariance matrix of all the variables in the model, and the fit is based only on these values, plus the sample sizes (in early SEM software you typically had to provide the covariance matrix directly, rather than working with the raw data). Nonetheless, because path analysis is an extension of regression techniques it is possible to request that intercepts are included in the model, and means estimated, by adding meanstructure=TRUE to the sem() function (see the lavaan manual for details). In the output below we now also see a table labelled ‘Intercepts’ which gives the mean values of each variable when it’s predictors are zero (just like in linear regression): mediation.fit.means &lt;- sem(mediation.model, meanstructure=T, data=mediation.df) summary(mediation.fit.means) ## lavaan (0.5-23.1097) converged normally after 16 iterations ## ## Number of observations 200 ## ## Estimator ML ## Minimum Function Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 0.166 0.075 2.198 0.028 ## m 0.190 0.070 2.721 0.007 ## m ~ ## x 0.530 0.067 7.958 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 10.629 0.362 29.323 0.000 ## .m 5.097 0.070 72.298 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.967 0.097 10.000 0.000 ## .m 0.993 0.099 10.000 0.000 Tables of model coefficients If you want to present results from these models in table format, the parameterEstimates() function is useful to extract the relevant numbers as a dataframe. We can then manipulate and present this table as we would any other dataframe. In the example below we extract the parameter estimates, select only the regression parameters (~) and remove some of the columns to make the final output easier to read: parameterEstimates(mediation.fit.means) %&gt;% as_data_frame() %&gt;% rownames_to_column() %&gt;% mutate(term=paste(lhs, op, rhs)) %&gt;% rename(estimate=est, std.error = se, p.value=pvalue, statistic = z, conf.low=ci.lower, conf.hi=ci.upper) %&gt;% select(term, op, everything(), -lhs, -rhs) ## # A tibble: 9 x 9 ## term op rowname estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 y ~ x ~ 1 0.16570565 0.07539776 2.197753 2.796671e-02 ## 2 y ~ m ~ 2 0.18989637 0.06979726 2.720685 6.514674e-03 ## 3 m ~ x ~ 3 0.52976119 0.06656841 7.958147 1.776357e-15 ## 4 y ~~ y ~~ 4 0.96727307 0.09672731 10.000000 0.000000e+00 ## 5 m ~~ m ~~ 5 0.99275572 0.09927557 10.000000 0.000000e+00 ## 6 x ~~ x ~~ 6 1.12014957 0.00000000 NA NA ## 7 y ~1 ~1 7 10.62875295 0.36247576 29.322658 0.000000e+00 ## 8 m ~1 ~1 8 5.09667420 0.07049575 72.297607 0.000000e+00 ## 9 x ~1 ~1 9 -0.03640346 0.00000000 NA NA ## # ... with 2 more variables: conf.low &lt;dbl&gt;, conf.hi &lt;dbl&gt; lm(mpg~wt, data=mtcars) %&gt;% tidy(conf.int=T) %&gt;% names ## [1] &quot;term&quot; &quot;estimate&quot; &quot;std.error&quot; &quot;statistic&quot; &quot;p.value&quot; &quot;conf.low&quot; ## [7] &quot;conf.high&quot; parameterEstimates(mediation.fit.means) %&gt;% filter(op == &quot;~&quot;) %&gt;% mutate(term = paste(lhs, op, rhs)) %&gt;% select(term, everything(), -se, -lhs, -rhs, -op) %&gt;% pander(caption=&quot;Regression parameters from `mediation.fit`&quot;) Regression parameters from mediation.fit term est z pvalue ci.lower ci.upper y ~ x 0.1657 2.198 0.02797 0.01793 0.3135 y ~ m 0.1899 2.721 0.006515 0.0531 0.3267 m ~ x 0.5298 7.958 1.776e-15 0.3993 0.6602 Diagrams Because describing path, CFA and SEM models in words can be tedious and difficult for readers to follow it is conventional to include a diagram of (at least) your final model, and perhaps also initial or alternative models. The semPlot:: package makes this relatively easy: passing a fitted lavaan model to the semPaths() function produces a line drawing, and gives the option to overlap raw or standardised coefficients over this drawing: # unfortunately semPaths plots very small by default, so we set # some extra parameters to increase the size to make it readable semPlot::semPaths(mediation.fit, &quot;par&quot;, sizeMan = 15, sizeInt = 15, sizeLat = 15, edge.label.cex=1.5, fade=FALSE) "],
["cfa.html", "Confirmatory factor analysis (CFA)", " Confirmatory factor analysis (CFA) Open some data and check that all looks well: hz &lt;- lavaan::HolzingerSwineford1939 hz %&gt;% glimpse() ## Observations: 301 ## Variables: 15 ## $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, ... ## $ sex &lt;int&gt; 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2... ## $ ageyr &lt;int&gt; 13, 13, 13, 13, 12, 14, 12, 12, 13, 12, 12, 12, 12, 12,... ## $ agemo &lt;int&gt; 1, 7, 1, 2, 2, 1, 1, 2, 0, 5, 2, 11, 7, 8, 6, 1, 11, 5,... ## $ school &lt;fctr&gt; Pasteur, Pasteur, Pasteur, Pasteur, Pasteur, Pasteur, ... ## $ grade &lt;int&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7... ## $ x1 &lt;dbl&gt; 3.333333, 5.333333, 4.500000, 5.333333, 4.833333, 5.333... ## $ x2 &lt;dbl&gt; 7.75, 5.25, 5.25, 7.75, 4.75, 5.00, 6.00, 6.25, 5.75, 5... ## $ x3 &lt;dbl&gt; 0.375, 2.125, 1.875, 3.000, 0.875, 2.250, 1.000, 1.875,... ## $ x4 &lt;dbl&gt; 2.333333, 1.666667, 1.000000, 2.666667, 2.666667, 1.000... ## $ x5 &lt;dbl&gt; 5.75, 3.00, 1.75, 4.50, 4.00, 3.00, 6.00, 4.25, 5.75, 5... ## $ x6 &lt;dbl&gt; 1.2857143, 1.2857143, 0.4285714, 2.4285714, 2.5714286, ... ## $ x7 &lt;dbl&gt; 3.391304, 3.782609, 3.260870, 3.000000, 3.695652, 4.347... ## $ x8 &lt;dbl&gt; 5.75, 6.25, 3.90, 5.30, 6.30, 6.65, 6.20, 5.15, 4.65, 4... ## $ x9 &lt;dbl&gt; 6.361111, 7.916667, 4.416667, 4.861111, 5.916667, 7.500... Defining the model As noted above, to define models in lavaan you must specify the relationships between variables in a text format. A full guide to this lavaan model syntax is available on the project website. For CFA models, like path models, the format is fairly simple, and resembles a series of linear models, written over several lines. In the model below there are three latent variables, visual, writing and maths. The latent variable names are followed by =~ which means ‘is manifested by’, and then the observed variables, our measures for the latent variable, are listed, separated by the + symbol. hz.model &lt;- &#39; visual =~ x1 + x2 + x3 writing =~ x4 + x5 + x6 maths =~ x7 + x8 + x9&#39; Note that we have saved our model specification/syntax in a variable named hz.model. The other special symbols in the lavaan syntax which can be used for CFA models are: a ~~ b, which represents a covariance. a ~~ a, which is a variance (you can think of this as the covariance of a variable with itself) To run the analysis we again pass the model specification and the data to the cfa() function: hz.fit &lt;- cfa(hz.model, data=hz) hz.fit %&gt;% tidy ## # A tibble: 24 x 8 ## term op estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 visual =~ x1 =~ 1.0000000 0.00000000 NA NA ## 2 visual =~ x2 =~ 0.5535003 0.09966512 5.553601 2.798440e-08 ## 3 visual =~ x3 =~ 0.7293702 0.10910970 6.684742 2.313327e-11 ## 4 writing =~ x4 =~ 1.0000000 0.00000000 NA NA ## 5 writing =~ x5 =~ 1.1130766 0.06542011 17.014288 0.000000e+00 ## 6 writing =~ x6 =~ 0.9261462 0.05544886 16.702711 0.000000e+00 ## 7 maths =~ x7 =~ 1.0000000 0.00000000 NA NA ## 8 maths =~ x8 =~ 1.1799508 0.16498657 7.151799 8.564260e-13 ## 9 maths =~ x9 =~ 1.0815302 0.15116744 7.154518 8.397727e-13 ## 10 x1 ~~ x1 ~~ 0.5490540 0.11360092 4.833182 1.343676e-06 ## # ... with 14 more rows, and 2 more variables: conf.low &lt;dbl&gt;, ## # conf.hi &lt;dbl&gt; summary(hz.fit, standardized=TRUE) ## lavaan (0.5-23.1097) converged normally after 35 iterations ## ## Number of observations 301 ## ## Estimator ML ## Minimum Function Test Statistic 85.306 ## Degrees of freedom 24 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual =~ ## x1 1.000 0.900 0.772 ## x2 0.554 0.100 5.554 0.000 0.498 0.424 ## x3 0.729 0.109 6.685 0.000 0.656 0.581 ## writing =~ ## x4 1.000 0.990 0.852 ## x5 1.113 0.065 17.014 0.000 1.102 0.855 ## x6 0.926 0.055 16.703 0.000 0.917 0.838 ## maths =~ ## x7 1.000 0.619 0.570 ## x8 1.180 0.165 7.152 0.000 0.731 0.723 ## x9 1.082 0.151 7.155 0.000 0.670 0.665 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## visual ~~ ## writing 0.408 0.074 5.552 0.000 0.459 0.459 ## maths 0.262 0.056 4.660 0.000 0.471 0.471 ## writing ~~ ## maths 0.173 0.049 3.518 0.000 0.283 0.283 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .x1 0.549 0.114 4.833 0.000 0.549 0.404 ## .x2 1.134 0.102 11.146 0.000 1.134 0.821 ## .x3 0.844 0.091 9.317 0.000 0.844 0.662 ## .x4 0.371 0.048 7.779 0.000 0.371 0.275 ## .x5 0.446 0.058 7.642 0.000 0.446 0.269 ## .x6 0.356 0.043 8.277 0.000 0.356 0.298 ## .x7 0.799 0.081 9.823 0.000 0.799 0.676 ## .x8 0.488 0.074 6.573 0.000 0.488 0.477 ## .x9 0.566 0.071 8.003 0.000 0.566 0.558 ## visual 0.809 0.145 5.564 0.000 1.000 1.000 ## writing 0.979 0.112 8.737 0.000 1.000 1.000 ## maths 0.384 0.086 4.451 0.000 1.000 1.000 Model output The output has three parts: Parameter estimates. The values in the first column are the standardised weights from the observed variables to the latent factors. Factor covariances. The values in the first column are the covariances between the latent factors. Error variances. The values in the first column are the estimates of each observed variable’s error variance. Plotting models As before, we can use the semPaths() function to visualise the model. This is an important step because it helps explain the model to others, and also gives you an opportunity to check you have specified your model correctly. semPlot::semPaths(hz.fit) And for ‘final’ models we might want to overplot model parameter estimates (in this case, standardised): # std refers to standardised estimates. &quot;par&quot; would plot # the unstandardised estimates semPlot::semPaths(hz.fit, &quot;std&quot;) "],
["model-fit.html", "Model fit", " Model fit To examine the model fit we use fitmeasures() and pass a list of the names of the fit indices we would like calculated: library(lavaan) fitmeasures(hz.fit, c(&#39;cfi&#39;, &#39;rmsea&#39;, &#39;rmsea.ci.upper&#39;, &#39;bic&#39;)) ## cfi rmsea rmsea.ci.upper bic ## 0.931 0.092 0.114 7595.339 This looks OK, but the fit indices indicate the model could be improved. In particular the RMSEA figure is above 0.05. See the notes on goodness of fit statistics for more detail. "],
["modification-indices.html", "Modification indices", " Modification indices To examine the modification indices we type: modificationindices(hz.fit) But because this function produces a very long table of output, it can be helpful to sort and filter the rows to show only those model modifications which might be of interes to us. The command below converts the output of modificationindices() to a dataframe. It then: Sorts the rows by the mi column, which represents the change in model 2 we see if the path was included (see sorting) Filters the results to show only those with 2 change &gt; 5 Selects only the lhs, op, rhs, mi, and epc columns. modificationindices(hz.fit) %&gt;% as_data_frame() %&gt;% arrange(-mi) %&gt;% filter(mi &gt; 5) %&gt;% select(lhs, op, rhs, mi, epc) %&gt;% pander(caption=&quot;Largest MI values for hz.fit&quot;) Largest MI values for hz.fit lhs op rhs mi epc visual =~ x9 36.41 0.577 x7 ~~ x8 34.15 0.5364 visual =~ x7 18.63 -0.4219 x8 ~~ x9 14.95 -0.4231 writing =~ x3 9.151 -0.2716 x2 ~~ x7 8.918 -0.1827 writing =~ x1 8.903 0.3503 x2 ~~ x3 8.532 0.2182 x3 ~~ x5 7.858 -0.1301 visual =~ x5 7.441 -0.2099 x1 ~~ x9 7.335 0.1379 x4 ~~ x6 6.22 -0.2348 x4 ~~ x7 5.92 0.09818 x1 ~~ x7 5.42 -0.1291 x7 ~~ x9 5.183 -0.1867 The lhs (left hand side), rhs (right hans side) and op (operation) columns specify what modification should be made. Latent factor to variable links have =~ in the ‘op’ column. Error covariances for observed variables have ~~ as the op. These symbols match the symbols used to describe a path in the lavaan model syntax. If we add the largest MI path to our model it will look like this: # same model, but with x9 now loading on visual hz.model.2 &lt;- &quot; visual =~ x1 + x2 + x3 + x9 writing =~ x4 + x5 + x6 maths =~ x7 + x8 + x9&quot; hz.fit.2 &lt;- cfa(hz.model.2, data=hz) fitmeasures(hz.fit.2, c(&#39;cfi&#39;, &#39;rmsea&#39;, &#39;rmsea.ci.upper&#39;, &#39;bic&#39;)) ## cfi rmsea rmsea.ci.upper bic ## 0.967 0.065 0.089 7568.123 RMSEA has improved somewhat, but we’d probably want to investigate this model further, and make additional improvements to it (although see the notes on model improvements) "],
["model-improvement.html", "Model modification and improvement", " Model modification and improvement Modification indices are a way of improving your model by identifying parameters which, if included, would improve model fit (or constraints removed). However, remember that: Use of modification indices should be informed by theory MI may suggest paths which don’t make substantive sense It’s very important to avoid adding paths in a completely data-driven way because this is almost certain to lead to over-fitting. It’s also important to work one step at a time, because the table of modification indices may change as you add additional paths. For example, the path second largest MI value may change once you add the path with the largest MI to the model. The basic steps to follow are: Run a simple, theoretically-derived model Notice it fits badly Add any additional paths which make theoretical sense Check GOF; If it still fits badly then, Run MI and identify the largest value If this parameter makes theoretical sense, relax the constraint Re-run the model and return to step 4 "],
["sem.html", "Structural eqution modelling (SEM)", " Structural eqution modelling (SEM) Combining Path models and CFA to create structural equation models (SEM) allows researchers to combine allow for measurment imperfection whilst also (attempting to) infer information about causation. SEM involves adding paths to CFA models which are, like predictors in standard regression models, are assumed to be causal in nature; i.e. rather than variables \\(x\\) and \\(y\\) simply covarying with one another, we are prepared to make the assumption that \\(x\\) causes \\(y\\). It’s worth pointing out though, right from the offset, that causal relationships drawn from SEM models always dependent on assumptions we are prepared to make when setting up our model. There is nothing magical in the technique that makes allows us to infer causality from non-experimental data (although note SEM can be used for some experimental analyses). It is only be our substantive knowledge of the domain that makes any kind of causal inference reasonable, and when using SEM the onus is always on us to check our assumptions, provide sensitivity analyses which test alternative causal models, and interpret observational data cautiously. [Note, there are techniques which use SEM as a means to make stronger kinds of causal statements, for example instrumental variable analysis, but even here, inferring causality still requires that we make strong assumptions about the process which generated our data. Nonetheless, with these caveats in mind, SEM can be a useful technique to quantify relationships been observed variables where we have measurement error, and especially where we have a theoretical model linking these observations. Steps to running an SEM Identify and test the fit of a measurement model. This is a CFA model which includes all of your observed variables, arranged in relation to the latent variables you think generated the data, and where covariances between all these latent variables are included. This step many include many rounds of model fitting and modification. Ensure your measurement model fits the data adequately before continuing. Test alternative or simplified measurements models and report where these perform well (e.g. are close in fit to your desired model). SEM models that are based on a poorly fitting measurment model will produce parameter estimates that are imprecise, unstable or both, and you should not proceed unless an adequately fitting measrement model is founds (see this nice discussion, which includes relevant references). Convert your measurement model by removing covariances between latent variables, and including new structural paths. Test model fit, and interpret the paths of interest. Avoid making changes to the measurement part of the model at this stage. Where the model is complex consider adjusting p values to allow for multuple comparisons (if using NHST). Test alternative models (e.g. with paths removed or reversed). Report where alternatives also fit the data. In writing up, provide sufficient detail for other researchers to replicate your analyses, and to follow the logic of the ammendments you make. Ideally share your raw data, but at a minimum share the covariance matrix. Report GOF statistics, and follow published reporting guidelines for SEM. Always include a diagram of your final model (at the least). A worked example: Building from a measurement model to SEM Imagine we have some data from a study that aimed to test the theory of planned behaviour. Researcher measured exercise and intentions, along with multiple measures of attitudes, social norms and percieved behavioural control. tpb.df %&gt;% psych::describe(fast=T) ## vars n mean sd min max range se ## a1 1 469 0.09 1.59 -4.88 5.09 9.97 0.07 ## a2 2 459 -0.05 1.21 -3.85 3.15 7.00 0.06 ## a3 3 487 0.02 1.10 -3.30 3.57 6.88 0.05 ## sn1 4 487 0.02 1.54 -4.86 4.47 9.33 0.07 ## sn2 5 487 0.04 1.20 -3.14 3.12 6.26 0.05 ## sn3 6 487 0.02 1.13 -2.96 4.03 6.99 0.05 ## sn4 7 471 -0.03 1.10 -3.42 2.79 6.20 0.05 ## pc1 8 487 -0.13 1.45 -4.71 4.13 8.84 0.07 ## pc2 9 487 0.02 1.25 -3.99 3.81 7.80 0.06 ## pc3 10 487 -0.08 1.27 -3.30 3.63 6.93 0.06 ## pc4 11 487 0.01 1.04 -3.85 3.34 7.19 0.05 ## pc5 12 487 -0.03 1.19 -3.39 4.19 7.58 0.05 ## intention 13 469 9.97 2.47 3.51 19.61 16.10 0.11 ## exercise 14 487 79.87 18.07 20.00 147.00 127.00 0.82 There were some missing data, but nothing to suggest a systematic pattern. For the moment we continue with standard methods: mice::md.pattern(tpb.df) ## a3 sn1 sn2 sn3 pc1 pc2 pc3 pc4 pc5 exercise sn4 a1 intention a2 ## 416 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 ## 16 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 ## 23 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 ## 11 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 ## 13 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 ## 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 2 ## 2 1 1 1 1 1 1 1 1 1 1 0 1 1 0 2 ## 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 2 ## 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 ## 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 2 ## 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 3 ## 0 0 0 0 0 0 0 0 0 0 16 18 18 28 80 We start by fitting a measurement model. The model sytax includes lines with =~ separatatig left and right hand side (to define the latents) ~~ to specify latent covariances We are not including exercise and intention yet because these are observed variables only (we don’t have multiple measurements for them) and so they don’t need to be in the measurement model: mes.mod &lt;- &#39; # the &quot;measurement&quot; part, defining the latent variables AT =~ a1 + a2 + a3 + sn1 SN =~ sn1 + sn2 + sn3 + sn4 PBC =~ pc1 + pc2 + pc3 + pc4 + pc5 # note that lavaan automatically includes latent covariances # but we can add here anyway to be explicit AT ~~ SN SN ~~ PBC AT ~~ PBC &#39; We can fit this model to the data like so: mes.mod.fit &lt;- cfa(mes.mod, data=tpb.df) summary(mes.mod.fit) ## lavaan (0.5-23.1097) converged normally after 54 iterations ## ## Used Total ## Number of observations 429 487 ## ## Estimator ML ## Minimum Function Test Statistic 58.845 ## Degrees of freedom 50 ## P-value (Chi-square) 0.183 ## ## Parameter Estimates: ## ## Information Expected ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## AT =~ ## a1 1.000 ## a2 0.408 0.050 8.081 0.000 ## a3 0.312 0.044 7.078 0.000 ## sn1 -0.076 0.205 -0.371 0.711 ## SN =~ ## sn1 1.000 ## sn2 0.509 0.156 3.254 0.001 ## sn3 0.403 0.125 3.219 0.001 ## sn4 0.369 0.115 3.199 0.001 ## PBC =~ ## pc1 1.000 ## pc2 0.732 0.079 9.239 0.000 ## pc3 0.777 0.083 9.366 0.000 ## pc4 0.381 0.061 6.258 0.000 ## pc5 0.674 0.076 8.884 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## AT ~~ ## SN 1.384 0.445 3.108 0.002 ## SN ~~ ## PBC 0.145 0.090 1.606 0.108 ## AT ~~ ## PBC 0.112 0.092 1.223 0.221 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .a1 0.433 0.195 2.214 0.027 ## .a2 1.138 0.085 13.336 0.000 ## .a3 1.040 0.075 13.932 0.000 ## .sn1 1.046 0.214 4.876 0.000 ## .sn2 1.060 0.088 11.975 0.000 ## .sn3 1.025 0.078 13.131 0.000 ## .sn4 0.965 0.072 13.341 0.000 ## .pc1 1.125 0.118 9.570 0.000 ## .pc2 0.959 0.084 11.463 0.000 ## .pc3 1.002 0.089 11.202 0.000 ## .pc4 0.933 0.068 13.788 0.000 ## .pc5 0.976 0.081 12.018 0.000 ## AT 2.155 0.260 8.283 0.000 ## SN 1.503 0.758 1.984 0.047 ## PBC 1.029 0.154 6.692 0.000 And we can assess model fit using fitmeasures. Here we select a subset of the possible fit indices to keep the output manageable. useful.fit.measures &lt;- c(&#39;chisq&#39;, &#39;rmsea&#39;, &#39;cfi&#39;, &#39;aic&#39;) fitmeasures(mes.mod.fit, useful.fit.measures) ## chisq rmsea cfi aic ## 58.845 0.020 0.989 16095.222 This model looks pretty good (see the guide to fit indices), but still check modification indices to identify improvements. If they made theoretical sense we might choose to add paths: modificationindices(mes.mod.fit) %&gt;% as_data_frame() %&gt;% filter(mi&gt;4) %&gt;% arrange(-mi) %&gt;% pander(caption=&quot;Modification indices for the measurement model&quot;) Modification indices for the measurement model lhs op rhs mi epc sepc.lv sepc.all sepc.nox AT =~ sn2 18.38 0.4607 0.6763 0.5619 0.5619 sn1 ~~ sn2 10.16 -0.318 -0.318 -0.1723 -0.1723 AT =~ sn4 9.234 -0.2651 -0.3892 -0.3598 -0.3598 a1 ~~ sn2 4.938 0.1793 0.1793 0.09262 0.09262 a2 ~~ sn2 4.555 0.125 0.125 0.08495 0.08495 However, in this case unless we had substantive reasons to add the paths, it would probably be reasonable to continue with the original model. Measurement model fits, so proceed to SEM Our SEM model adapts the CFA (measurement model), including additional observed variables (e.g. intention and exercise) and any relevant structural paths: sem.mod &lt;- &#39; # this section identical to measurement model AT =~ a1 + a2 + a3 + sn1 SN =~ sn1 + sn2 + sn3 + sn4 PBC =~ pc1 + pc2 + pc3 + pc4 + pc5 # additional structural paths intention ~ AT + SN + PBC exercise ~ intention &#39; We can fit it as before, but now using the sem() function rather than the cfa() function: sem.mod.fit &lt;- cfa(sem.mod, data=tpb.df) The first thing we do is check the model fit: fitmeasures(sem.mod.fit, useful.fit.measures) ## chisq rmsea cfi aic ## 185.866 0.062 0.921 20651.995 RMSEA is slightly higher than we like, so we can check the modification indices: sem.mi &lt;- modificationindices(sem.mod.fit) %&gt;% as_data_frame() %&gt;% arrange(-mi) sem.mi %&gt;% head(6) %&gt;% pander(caption=&quot;Top 6 modification indices for the SEM model&quot;) Top 6 modification indices for the SEM model lhs op rhs mi epc sepc.lv sepc.all sepc.nox PBC ~ exercise 163.5 0.04515 0.04491 0.8218 0.8218 PBC =~ intention 97.11 1.136 1.142 0.4581 0.4581 SN =~ intention 96.11 0.8495 1.104 0.4427 0.4427 exercise ~ PBC 84.5 5.944 5.976 0.3265 0.3265 AT =~ intention 84.29 0.6897 0.994 0.3986 0.3986 PBC ~ intention 78.83 0.252 0.2506 0.6249 0.6249 Interestingly, this model suggests two additional paths involving exercise and the PBC latent: sem.mi %&gt;% filter(lhs %in% c(&#39;exercise&#39;, &#39;PBC&#39;) &amp; rhs %in% c(&#39;exercise&#39;, &#39;PBC&#39;)) %&gt;% pander() lhs op rhs mi epc sepc.lv sepc.all sepc.nox PBC ~ exercise 163.5 0.04515 0.04491 0.8218 0.8218 exercise ~ PBC 84.5 5.944 5.976 0.3265 0.3265 Of these suggested paths, the largest MI is for the one which says PBC is predicted by exercise. However, the model would also be improved by allowing PBC to predict exercise. Which should we add? The answer will depend on both previous theory and knowledge of the data. If it were the case that exercise was measured at a later time point than PBC. In this case the decision is reasonably clear, because the temporal sequencing of observations would determine the most likely path. These data were collected contemporaneously, however, and so we can’t use our design to differentiate the causal possibilities. Another consideration would be that, by adding a path from exercise to PBC we would make the model non-recursive, and likely non-identified. A theorist might also argue that because previous studies, and the theory of planned behaviour itself, predict that PBC may exert a direct influence on behaviour, we should add the path with the smaller MI (so allow PBC to predict exercise). In this case, the best course of action would probably be to report the theoretically implied model, but also test alternative models in which causal relations between the variables are reversed or otherwise altered (along with measures of fit and key parameter estimates). The discussion of your paper would then make the case for your preferred account, but make clear that the data were (most likely) unable to provide a persuasive case either way, and that alternative explanations cannot be ruled out. Interpreting and presenting key parameters One of the best ways to present estimates from your final model is in a diagram, because this is intutive and provides a simple way for readers to comprehend the paths implied by your model. We can automatically generate a plot from a fitted model using semPaths(). Here, the what='std' is requesting standardised parameter estimates be shown. Adding residuals=F hides variances of observed and latent variables, which are not of interest here. The line thicknesses are scaled to represent the size parameter itself: semPlot::semPaths(sem.mod.fit, what=&#39;std&#39;, residuals=F) For more information on reporting SEM however, see Schreiber et al. (2006). References "],
["identification.html", "‘Identification’ in CFA and SEM", " ‘Identification’ in CFA and SEM Identification refers to the idea that a model is ‘estimable’, or more specifically whether there is a single best solution for the parameters specified in the model. An analogy would be the ‘line of best fit’ in regression - if we could draw two lines that fit the data equally well then our method doesn’t enable us to choose between these possibilities, and is essentially meaningless (or uninterpretable, anyway). This is a complex topic, but David Kenny has an excellent page here which covers identification in lots of detail: http://davidakenny.net/cm/identify.htm. Some of the key ideas to takeaway are: Feedback loops and other non-recursive models are likely to cause problems without special attention. Latent variables need a scale. To do this either fix their variance, or fix a factor loading to 1. You need ‘enough data’. Normally this will be at least 3 measured variables per latent. Sometimes 2 is enough, provided the errors of these variables are uncorrelated, but you may struggle to fit models because of ‘empirical under-identification’1 If a model is non-identified, it may either i) fail to run or, worse, ii) produce spurious results. Rule B For structural models, ‘Rule B’ also applies when deciding when a model is identified: No more than one of the following statements should be true about variables or latents in your model: X directly causes Y Y directly causes X X and Y have a correlated disturbance X and Y are correlated exogenous variables But see http://davidakenny.net/cm/identify_formal.htm#RuleB for a proper explanation. Note, indicators themselves should be correlated with one another in a bivariate correlation matrix. It’s only the errors which should be uncorrelated.↩ "],
["cfa-sem-missing-data.html", "Missing data", " Missing data If you have missing data you can use the missing = &quot;ML&quot; argument to ask lavaan to estimate the ‘full information maximum likelihood’ (see http://lavaan.ugent.be/tutorial/est.html). # fit ML model including mean structure to make comparable with FIML fit below # (means are always included with FIML model fits) sem.mod.fit &lt;- sem(sem.mod, data=tpb.df, meanstructure=TRUE) # fit again including missing data also sem.mod.fit.fiml &lt;- sem(sem.mod, data=tpb.df, missing=&quot;ML&quot;) It doesn’t look like the parameter estimates change much. To compare them explicitly we can extract the relevant coefficients from each (they don’t look all that different): library(apastats) bind_cols( parameterestimates(sem.mod.fit) %&gt;% select(lhs, op, rhs, est, pvalue) %&gt;% rename(ml=est, ml.p = pvalue), parameterestimates(sem.mod.fit.fiml) %&gt;% transmute(fiml=est, fiml.p = round.p(pvalue))) %&gt;% filter(op==&quot;~&quot;) %&gt;% mutate(ml = t.round(ml), fiml = t.round(fiml), ml.p = round.p(ml.p)) %&gt;% pander(&quot;Comparison of ML and MLM parameter estimates.&quot;) Comparison of ML and MLM parameter estimates. lhs op rhs ml ml.p fiml fiml.p intention ~ AT 0.28 = .115 0.32 = .054 intention ~ SN 0.45 = .043 0.48 = .017 intention ~ PBC 1.01 &lt; .001 1.04 &lt; .001 exercise ~ intention 5.76 &lt; .001 5.74 &lt; .001 -->"]
]
